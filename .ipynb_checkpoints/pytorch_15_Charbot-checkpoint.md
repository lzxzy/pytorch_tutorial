# ChatBot Tutorial
这篇教程中，我们将探索一个递归sequence-to-sequence模型有趣的使用场景。我们将使用康奈尔电影对话预料库来训练一个简单的对话机器人。

对话模型在人工智能研究中是一个热点。对话机器人存在于许多场景中，例如售货服务和在线助手等。这些机器人通常依赖基于经验的模型，即输出预先定义好的回答。在非常特定的领域如公司IT助理，这种模型可能会有效，但是，在开放通用领域使用环境下它们还不够鲁棒。教会机器与人类在多领域下进行有意义的对话仍然是有待解决的研究问题。近来，深度学习爆炸已经允许我们实现更有效的生成模型如Google的神经对话模型，标志着多领域对话生成模型的一大进步。本教程，我们将用PyTorch实现这种模型。

**Tutorial Highlights**
+ 处理和加载数据集
+ 实现sequence-to-sequence模型
+ 使用mini-batch对encoder&decoder进行联合训练
+ 实现贪婪搜索decoding模型
+ 与训练好的聊天机器人交互

## Preparation
在开始前，下载数据压缩文件并放到`data/`文件夹下。然后引入必要的包。
### Load & Preprocess Data
接下来是重新组织数据文件并且将数据加载到我们可以处理的结构中。
CMDC数据集包含有丰富的电影角色对话：
+ 10292对电影角色的220579个会话交流
+ 来自617部电影的9035个角色
+ 总发言量304713

该数据集足够庞大和丰富，同时对话形式有很大差异，时态，情感等。我们的目标是利用如此丰富的数据集来使得我们的模型对于各种形式的输入和要求具有鲁棒性。
### Create formatted data file
为了方便起见，我们将创建一个漂亮的数据文件格式，每一行包含用tab分离的查询语句和回答句子对。

下面的函数便于解析movie_lines.txt 数据文件
+ `loadLines` 将每行数据分离并变为字典形式（lineID, characterID, movieID, character, text）
+ `loadConversations` 基于*movie_conversations.txt*组织来自`loadLines`的数据变为对话
+ `extractSentencePairs`从对话中抽取一对句子

### Load and trim data
我们接下来的业务顺序是创建一个词典并且加载查询/响应句子对到内存中。

我们处理的句子由一系列单词组成，并不包含离散数值空间的映射。因此，我们必须创建一个对独立单词的映射。

首先定义一个`Voc`类，保存从单词到索引的映射，一个反向的从索引到单词的映射，每个单词和所有单词的统计。类中提供添加单词到词表的方法`addWard`,将一个句子中所有单词加到字典的方法`addSentence`,以及剔除不频繁见到的单词`trim`方法。

现在我们可以将字典和查询/回答句子对集成。在我们准备使用数据前，我们必须进行一些处理。

首先，我们必须将Unicode编码字符转换为ASCII编码使用`unicodeToAscii`. 接着，我们要将所有字母转换为小写并剔除所有非字符符号变为单词原型`normalizeString`。最后，为了达到训练收敛的目标，我们将过滤长度大于`MAX_LENGTH`的句子`filterPairs`

为了在训练中实现快速收敛的另一个技巧是从词表中剔除几乎不使用的单词。减少特征空间也会减弱模型学习的困难程度。我们将做两个步骤：

1、使用`voc.trim`函数，剔除阈值`MIN_COUNT`之下的单词

2、用剔除后的单词过滤输出句子对

## Prepare Data for Models

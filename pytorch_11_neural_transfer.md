# PyTorch
## Neural Transfer using pytorch
### INtroduction
本章介绍如何实现由Leon A. Gatys, Alexander S. Ecker and Matthias Bethge提出的风格转换算法。风格转换或者说风格迁移，允许你对一张图片进行处理生成新的艺术风格。算法接受三张图片， 一个输入图片，一个内容图片，一个风格图片，然后对输入图片进行处理使之内容与内容图片，艺术风格与风格图片相似。

### Underlying Principle
遵循的法则十分朴素：我们定义两个距离，一个对应内容($D_c$)另一个对应风格($D_s$)。$D_c$度量两张图片的内容差异同时$D_s$度量两张图片的风格差异。然后，我们拿第三张输入图片，对其进行迁移变换同时最小化内容距离和风格距离。
### Importing Packages and Selecting a Device
### Loading the Images
原始的PIL 图片中的值范围从0 到 255, 当转换为torch tenors对象，它们的值变为0到1。所有图片也需要进行维度调整保持维度一致。如果你尝试给网络传递值为0到255的tenosr图像，那么激活特征图将无法感知内容和风格信息。但是，来自caffe的预训练模型所训练的图片值的范围为0到255。
### Loss Function
**Content Loss**

内容损失函数是一个对独立的层的加权内容距离。函数接受$L$层的特征图$F_{XL}$并返回输入图片$x$和内容图片$c$之间的图片加权内容距离$w_{CL}\cdot D^L_C(X,C)$。为了计算距离,函数必须知道内容图片的特征图$F_{CL}$。我们通过`torch.nn.Module`实现这个函数，构造函数接受$F_{CL}$作为输入，两个特征图集合间的距离使用均方差$||F_{XL} - F_{CL}||^2$, 可以通过`nn.MSELoss`实现。

在通过卷积层后直接添加内容损失模块来计算内容距离。通过这种方式每次网络输入一张输入图片，内容距离在特定的层被计算得到并且由于`autograd`，所有的梯度被计算。现在，为了使得内容损失层容易计算，我们定义`forward`方法，用来计算内容损失并返回输入。计算得到的loss被当作参数保存在模型中。

> detach(), 截止反向梯度传播，计算损失但不会进行反向传播。

**Style Loss**

风格损失的实现与内容损失类似。它充当网络中的`transparent layer`计算分格损失。为了计算风格损失，我们首先计算格莱姆矩阵`gram matrix`$G_{XL}$(一种用来保存风格信息的矩阵，详细信息额外查阅)。gram matrix是给定矩阵与其转置点乘的结果。在这个例子中是对某层特征图$F_{XL}$进行重置后的矩阵。$F_{XL}$重置为$\hat{F}_{XL}$，一个$K * N$矩阵，k是特征层L的特征图数目，n是任意一个特征图$F^k_{KL}$向量化后的长度。例如$\hat{F}_XL$的第一行对应的是特征图$F^1_{XL}$向量。

最后，gram matrix必须被正则化，通过对每个元素除以矩阵总的元素个数。这种正则化是为了抵消$\hat{F}_{XL}$矩阵N维度过大导致Gram matrix的值过大。这些过大的值会在第一层（池化层之前）在梯度下降计算过程中产生较大影响。因此正则化十分重要。

### Importing the Model
现在我们需要引入一个预训练模型，同论文中所说的一样使用VGG-19

PyTorch所实现的VGG是一个被分成两个子`Squential`模型：`features`(包含卷积层和池化层)，和`classifier`(包含全连接层)。我们使用`features`模型，因为我们需要独立卷积层的输出来度量内容和分格损失。一些层在训练和推断过程中表现不同，因此我们将模型设置为推断模式`.eval()`

额外的，VGG网络在训练前，对图片的每个通道进行正则化均值[0.485, 0.456, 0.406]和标准差[0.229, 0.224, 0.225]，所以在图片输入网络之前我们也需要对图片进行正则化。

一个`Sequential`模型包含一个有序的子模型序列。例如，`vgg19.features`包含了一个队列（Conv2d, ReLU, MaxPool2d, Conv2d, ReLU…）以正确的深度排序。我们需要在卷积层之后加入内容损失和风格损失。为了实现这一目的，需要创建新的`Sequential`模型使得内容损失和分格损失被正确的插入。
### Gradient Descent
如算法的作者 Leon Gatys所建议的，我们将使用L-BFGS算法执行梯度下降， 不像训练神经网络，我们想对输入图片进行训练最小化内容和风格损失。通过创建PyTorch L-BFGS优化器`optim.LBFGS`并将图片转为tensor传递给优化器。

最后，需要创建一个函数来运行风格迁移模型。在每一次迭代，输入更新过的输入图片并计算新的loss。 将在每个损失函数模型上执行`backward`动态的计算它们的梯度。优化器需要一个“闭环”函数，重新评估模型并返回损失。

最后要说明的一点是，网络可能尝试对输入图像tensor超过0到1的值进行优化。可以通过网络每次执行时将输入修正到0 到1之间避免这一问题。
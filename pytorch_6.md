# Pytorch
## Transfer Learning 
本章学习如何使用迁移学习训练自己的模型。
> 在实际中，很少有人通过原始状态（随机初始化权重）训练一个完整的卷积神经网络，因为通常很少有足够大小的数据集供我们进行训练。一个替代方法是使用一个在大数据集上（例如ImageNet, 包含1000类，120万张图片）预训练的卷积网络，然后将这个网络的权重作为初始权重或者修改部分特征抽取器以应用在我们感兴趣的任务中。

迁移学习主要有如下两个使用场景：
+ 调优卷积网络：相比随机初始化网络，我们使用预训练网络初始化我们要训练的网络，好比于我们已经在imagenet 1000数据集上进行训练，剩余的训练看起来就和往常一样。
+ 将卷积网络作为特征抽取器： 在这个场景下，我们固定除最后一个全连接层之外的其他所有层。将最后的全连接层替换为一个新的随机初始的层进行训练。

### Load Data
我们使用`torchvision`和`torch.utils.data`两个包来加载数据。

我们将训练一个区分蚂蚁和蜜蜂的分类器。对于每个类别我们有120张训练图片，75张验证图片。通常来讲，如果从头开始训练，这个数据集过小而不足以覆盖所要学习的特征。因此使用迁移学习，我们应该可以获得一个较为理想的结果。

### Train the model
接下来我们将对模型进行训练，实现如下两点：
+ 对学习率自动调节
+ 保存最优模型
其中参数`scheduler`是一个学习率指导对象来自`torch.optim.lr_scheduler`
### ConvNet as fixed feature extractor
接下来我们需要固定除全连接层外所有层。我们需要将`requires_grad == False`来固定参数，使得在backward过程中不计算梯度。
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(root='data/', train=True, download=True,\n",
    "                                                          transform=transforms.Compose([\n",
    "                                                              transforms.ToTensor(),\n",
    "                                                              transforms.Normalize((0.1307,),(0.3081,))\n",
    "                                                          ])), batch_size = 64, shuffle = True, num_workers = 4)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(root='data/', train=False, \n",
    "                                                         transform=transforms.Compose([\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize((0.1307,), (0.3081,))\n",
    "                                                         ])), batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "        \n",
    "        self.fc_loc[2].weight.data.zero_()\n",
    "        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        \n",
    "    def stn(self, x):\n",
    "        xs = self.localization(x)\n",
    "        xs = xs.view(-1, 10 * 3 * 3)\n",
    "        theta = self.fc_loc(xs)\n",
    "        theta = theta.view(-1, 2, 3)\n",
    "        \n",
    "        grid = F.affine_grid(theta, x.size())\n",
    "        x = F.grid_sample(x, grid)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.stn(x)\n",
    "        \n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 500 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test():\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        print('\\n Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "              .format(test_loss, correct, len(test_loader.dataset),\n",
    "                      100. * correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.332689\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.170960\n",
      "\n",
      " Test set: Average loss: 0.9057, Accuracy: 7362/10000 (74%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.886189\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.326185\n",
      "\n",
      " Test set: Average loss: 0.0838, Accuracy: 9733/10000 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.394539\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.419149\n",
      "\n",
      " Test set: Average loss: 0.0733, Accuracy: 9760/10000 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.168806\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.185782\n",
      "\n",
      " Test set: Average loss: 0.0731, Accuracy: 9760/10000 (98%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.311886\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.204089\n",
      "\n",
      " Test set: Average loss: 0.0646, Accuracy: 9799/10000 (98%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.241806\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.179459\n",
      "\n",
      " Test set: Average loss: 0.0568, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.193199\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.089408\n",
      "\n",
      " Test set: Average loss: 0.0652, Accuracy: 9788/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.348430\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.033076\n",
      "\n",
      " Test set: Average loss: 0.0578, Accuracy: 9826/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.244688\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.166998\n",
      "\n",
      " Test set: Average loss: 0.0503, Accuracy: 9844/10000 (98%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.142640\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.048796\n",
      "\n",
      " Test set: Average loss: 0.0462, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.160136\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.264260\n",
      "\n",
      " Test set: Average loss: 0.0471, Accuracy: 9870/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.224524\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.055106\n",
      "\n",
      " Test set: Average loss: 0.0480, Accuracy: 9863/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.053437\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.059051\n",
      "\n",
      " Test set: Average loss: 0.0489, Accuracy: 9846/10000 (98%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.164228\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.294756\n",
      "\n",
      " Test set: Average loss: 0.0557, Accuracy: 9829/10000 (98%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.162517\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.075625\n",
      "\n",
      " Test set: Average loss: 0.0483, Accuracy: 9845/10000 (98%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.028481\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.033827\n",
      "\n",
      " Test set: Average loss: 0.0434, Accuracy: 9873/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.033326\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.105723\n",
      "\n",
      " Test set: Average loss: 0.0361, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.023485\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.088439\n",
      "\n",
      " Test set: Average loss: 0.0444, Accuracy: 9859/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.075089\n"
     ]
    }
   ],
   "source": [
    "def convert_image_np(inp):\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    return inp\n",
    "\n",
    "def visualize_stn():\n",
    "    with torch.no_grad():\n",
    "        data = next(iter(test_loader))[0].to(device)\n",
    "        \n",
    "        input_tensor = data.cpu()\n",
    "        transformed_input_tensor = model.stn(data).cpu()\n",
    "        \n",
    "        in_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(input_tensor))\n",
    "        \n",
    "        out_grid = convert_image_np(\n",
    "            torchvision.utils.make_grid(transformed_input_tensor))\n",
    "        \n",
    "        f, axarr = plt.subplots(1, 2)\n",
    "        axarr[0].imshow(in_grid)\n",
    "        axarr[0].set_title('Dataset Images')\n",
    "        \n",
    "        axarr[1].imshow(out_grid)\n",
    "        axarr[1].set_title('Transofrmed Images')\n",
    "        \n",
    "for epoch in range(1, 20 + 1):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    \n",
    "visualize_stn()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
